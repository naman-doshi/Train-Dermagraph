{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torchvision import models\n",
    "import pdb\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Initialisation\n",
    "Here we will construct a class denoting the dataset, and create several methods within it to eliminate some repetitiveness from the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelanomaDataset(Dataset):\n",
    "    def __init__(self, df, img_path_one, transforms=None, is_test=False):\n",
    "        self.df = df\n",
    "        self.img_path_one = img_path_one\n",
    "        self.transforms = transforms\n",
    "        self.is_test = is_test\n",
    "        \n",
    "    def __getitem__(self, indx):\n",
    "        img_path = f\"{self.img_path_one}/{self.df.iloc[indx]['image_name']}.jpg\"\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(**{\"image\": np.array(img)})[\"image\"]\n",
    "            \n",
    "        if self.is_test:\n",
    "            return img\n",
    "\n",
    "        target = self.df.iloc[indx]['target']\n",
    "        return img, torch.tensor([target], dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "Data augmentation is the process of increasing the amount of data available for training, and is especially relevant here as it can increase the accuracy of the model. This in turn makes sure that the patient/doctor receives a more accurate result — in the medical industry, every percent matters. An added benefit is that these alterations can make the model adapt better to images in 'strange' conditions (e.g. bad lighting, low resolution camera, wrong amount of zoom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmentations(p=0.5):\n",
    "\n",
    "    # Assigning the ImageNet mean and standard deviation to a variable\n",
    "    imagenet_stats = {'mean':[0.485, 0.456, 0.406], 'std':[0.229, 0.224, 0.225]}\n",
    "\n",
    "    # Using albumentations' augmentation pipeline to sequentially alter the images.\n",
    "    # The variable p stands for the percentage chance of a particular alteration happening.\n",
    "    train_tf = A.Compose([\n",
    "        A.Cutout(p=p),\n",
    "        A.RandomRotate90(p=p),\n",
    "        A.Flip(p=p),\n",
    "        A.OneOf([\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2,\n",
    "                                       contrast_limit=0.2,\n",
    "                                       ),\n",
    "            A.HueSaturationValue(\n",
    "                hue_shift_limit=20,\n",
    "                sat_shift_limit=50,\n",
    "                val_shift_limit=50)\n",
    "        ], p=p),\n",
    "        A.OneOf([\n",
    "            A.MotionBlur(p=0.2),\n",
    "            A.MedianBlur(blur_limit=3, p=0.1),\n",
    "            A.Blur(blur_limit=3, p=0.1),\n",
    "        ], p=p),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=p),\n",
    "        A.OneOf([\n",
    "            A.OpticalDistortion(p=0.3),\n",
    "            A.GridDistortion(p=0.1)\n",
    "        ], p=p), \n",
    "        ToTensor(normalize=imagenet_stats)\n",
    "        ])\n",
    "    \n",
    "    # The test dataset does not require augmentation\n",
    "    test_tf = A.Compose([\n",
    "        ToTensor(normalize=imagenet_stats)\n",
    "        ])\n",
    "\n",
    "    \n",
    "    return train_tf, test_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train / Validation Split\n",
    "- Any duplicate images must be removed\n",
    "- In accordance with Chris Deotte's triple-stratified K-Fold [model](https://www.kaggle.com/code/cdeotte/triple-stratified-kfold-with-tfrecords), the split will be conducted in a 80:20 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_split(df):\n",
    "    # Removal of duplicates\n",
    "    df = df[df.tfrecord != -1].reset_index(drop=True)\n",
    "\n",
    "    # Splitting\n",
    "    train_tf_records = list(range(len(df.tfrecord.unique())))[:12]\n",
    "    split_cond = df.tfrecord.apply(lambda x: x in train_tf_records)\n",
    "    train = df[split_cond].reset_index()\n",
    "    valid = df[~split_cond].reset_index()\n",
    "    return train, valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialisation\n",
    "- EfficientNet is a convolutional neural network architecture and scaling method that uniformly scales all dimensions of depth/width/resolution using a compound coefficient. \n",
    "- This makes it ideal for this project — by tinkering with which model is used (B0 until B7, with each model sequentially using more system resources and being more accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, model_name='efficientnet-b0', pool=F.adaptive_avg_pool2d):\n",
    "        super().__init__()\n",
    "        self.pool = pool\n",
    "        self.backbone = EfficientNet.from_pretrained(model_name)\n",
    "        in_features = getattr(self.backbone,'_fc').in_features\n",
    "        self.classifier = nn.Linear(in_features,1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.pool(self.backbone.extract_features(x),1)\n",
    "        features = features.view(x.size(0),-1)\n",
    "        return self.classifier(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the device to \"cuda\" if you have a GPU or \"cpu\" if you if you don't. Even mps is supported on Apple Silicon, it is not as fast as cpu.\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "def get_model(model_name='efficientnet-b0', lr=1e-5, wd=0.01, freeze_backbone=False, opt_fn=torch.optim.AdamW, device=None):\n",
    "    model = Model(model_name=model_name)\n",
    "\n",
    "    # Freezing Layers\n",
    "    if freeze_backbone:\n",
    "        for parameter in model.backbone.parameters():\n",
    "            parameter.requires_grad = False\n",
    "    \n",
    "    # Optimising weights\n",
    "    opt = opt_fn(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    model = model.to(device)\n",
    "    return model, opt\n",
    "\n",
    "# Training\n",
    "def training(xb, yb, model, loss_fn, opt, device, scheduler):\n",
    "    xb, yb = xb.to(device), yb.to(device)\n",
    "    out = model(xb)\n",
    "    opt.zero_grad()\n",
    "    loss = loss_fn(out,yb)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    scheduler.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Validation\n",
    "def validation(xb,yb,model,loss_fn,device):\n",
    "    xb,yb = xb.to(device), yb.to(device)\n",
    "    out = model(xb)\n",
    "    loss = loss_fn(out,yb)\n",
    "    out = torch.sigmoid(out)\n",
    "    return loss.item(),out\n",
    "\n",
    "def get_data(train_df, valid_df, train_tfms, test_tfms, bs):\n",
    "    train_ds = MelanomaDataset(df=train_df, img_path_one=path/'train', transforms=train_tfms)\n",
    "    valid_ds = MelanomaDataset(df=valid_df, img_path_one=path/'train', transforms=test_tfms)\n",
    "    train_dl = DataLoader(dataset=train_ds, batch_size=bs, shuffle=True, num_workers=4)\n",
    "    valid_dl = DataLoader(dataset=valid_ds, batch_size=bs*2, shuffle=False, num_workers=4)\n",
    "    return train_dl, valid_dl\n",
    "\n",
    "def fit(epochs, model, train_dl, valid_dl, opt, devic=None, loss_fn=F.binary_cross_entropy_with_logits):\n",
    "    devic = device\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, len(train_dl)*epochs)\n",
    "    val_rocs = [] \n",
    "    \n",
    "    #Creating progress bar\n",
    "    mb = master_bar(range(epochs))\n",
    "    mb.write(['epoch','train_loss','valid_loss','val_roc'],table=True)\n",
    "\n",
    "    for epoch in mb:    \n",
    "        trn_loss,val_loss = 0.0,0.0\n",
    "        val_preds = np.zeros((len(valid_dl.dataset),1))\n",
    "        val_targs = np.zeros((len(valid_dl.dataset),1))\n",
    "        \n",
    "        #Training\n",
    "        model.train()\n",
    "        \n",
    "        #For every batch \n",
    "        for xb,yb in progress_bar(train_dl,parent=mb):\n",
    "            trn_loss += training(xb,yb,model,loss_fn,opt,devic,scheduler) \n",
    "        trn_loss /= mb.child.total\n",
    "\n",
    "        #Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i,(xb,yb) in enumerate(progress_bar(valid_dl,parent=mb)):\n",
    "                loss,out = validation(xb, yb, model, loss_fn, devic)\n",
    "                val_loss += loss\n",
    "                bs = xb.shape[0]\n",
    "                val_preds[i*bs:i*bs+bs] = out.cpu().numpy()\n",
    "                val_targs[i*bs:i*bs+bs] = yb.cpu().numpy()\n",
    "\n",
    "        val_loss /= mb.child.total\n",
    "        val_roc = roc_auc_score(val_targs.reshape(-1),val_preds.reshape(-1))\n",
    "        val_rocs.append(val_roc)\n",
    "\n",
    "        mb.write([epoch,f'{trn_loss:.6f}',f'{val_loss:.6f}',f'{val_roc:.6f}'],table=True)\n",
    "    return model,val_rocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path/'train.csv')\n",
    "train_df, valid_df = get_train_val_split(df)\n",
    "train_tfms, test_tfms = get_augmentations(p=0.5)\n",
    "train_dl, valid_dl = get_data(train_df, valid_df, train_tfms, test_tfms, 16)\n",
    "model, opt = get_model(model_name='efficientnet-b0', lr=1e-4, wd=1e-4)\n",
    "model, val_rocs = fit(8, model, train_dl, valid_dl, opt)\n",
    "torch.save(model.state_dict(), f'effb0.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training does not work in Jupyter Notebooks, so refer to train.py to see the whole training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet B0, 1 TTA Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the code below does not work due to the Jupyter Notebooks environment. Please refer to train.py instead!\n",
    "model, opt = get_model(model_name='efficientnet-b0',lr=1e-4,wd=1e-4)\n",
    "model.load_state_dict(torch.load(f'effb0.pth', map_location=device))\n",
    "model.eval()\n",
    "test_df = pd.read_csv(path/'test.csv')\n",
    "test_ds = MelanomaDataset(df=test_df, img_path_one=path/'test',transforms=test_tfms, is_test=True)\n",
    "test_dl = DataLoader(dataset=test_ds, batch_size=32, shuffle=False,num_workers=4)\n",
    "\n",
    "tta = 1\n",
    "preds = np.zeros(len(test_ds))\n",
    "for tta_id in range(tta):\n",
    "    count = 0\n",
    "    test_preds = []\n",
    "    with torch.no_grad():\n",
    "        for xb in test_dl:\n",
    "            print(count)\n",
    "            xb = xb.to(device)\n",
    "            out = model.to(device)(xb)\n",
    "            out = torch.sigmoid(out)\n",
    "            test_preds.extend(out.cpu().detach().numpy())\n",
    "            count += 1\n",
    "        preds += np.array(test_preds).reshape(-1)\n",
    "    print(f'TTA {tta_id+1}')\n",
    "preds /= tta\n",
    "\n",
    "subm = pd.read_csv(path/'sample_submission.csv')\n",
    "subm.target = preds\n",
    "subm.to_csv('submissions/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With only one TTA iteration, this model was able to achieve a 0.8868 area under the ROC Curve:\n",
    "![Score](img/effb0tta1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet B0, 10 TTA Iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Score](img/effb0tta10.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
